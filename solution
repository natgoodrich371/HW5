!pip install spacy
!pip install newsapi-python
!pip install pickle-mixin
!python -m spacy download en_core_web_lg
from google.colab import drive
from newsapi import NewsApiClient
import spacy
import pickle
import wordcloud
import pandas as pd
import collections

nlp = spacy.load("en_core_web_sm")
newsapi = NewsApiClient(api_key='75c71376b6584fd2b6b77daef709a36e')
articles = newsapi.get_everything(q='coronavirus', language='en', from_param='2021-09-26', to='2021-10-24', sort_by='relevancy', page=1)
drive.mount('/drive')

filename = 'articlesCOVID.pckl'
pickle.dump(articles, open(filename, 'wb'))

filename = 'articlesCOVID.pckl'
loaded_model = pickle.load(open(filename, 'rb'))

filepath = '/drive/My Drive/Colab Notebooks/HW5'
pickle.dump(loaded_model, open(filepath, 'wb'))

data = []

for i, article in enumerate(articles):
  for x in articles['articles']:
    title = x['title']
    date = x['publishedAt']
    description = x['description']     
    content = x['content']
    data.append({'title':title, 'date':date, 'desc':description, 'content':content})

df = pd.DataFrame(data)
df = df.dropna()
df.head()

def get_keywords_eng(token):
  result = []
  punctuation = string.punctuation
  stop_words = stopwords.words('english')
  
  for i in token:
    if (i in stop_words or i in punctuation):
      continue
    else:
      result.append(i)

  return result

results = []

for content in df.content.values:
    content = tokenizer.tokenize(content)
    results.append([x[0] for x in Counter(get_keywords_eng(content)).most_common(5)])
df['keywords'] = results

text = str(results)
wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(text)
plt.figure()
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

df.to_csv('/drive/My Drive/Colab Notebooks/HW52.csv')

